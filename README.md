
# ğŸ“„ Classification de textes avec BERT (Politics vs World News)

## ğŸ§  Objectif

Ce projet a pour but de classer automatiquement des articles de presse en deux catÃ©gories :
- `Politics News` (Classe 0)
- `World News` (Classe 1)

Le modÃ¨le utilise un BERT prÃ©-entraÃ®nÃ©, affinÃ© (`fine-tuned`) sur un jeu de donnÃ©es d'articles labellisÃ©s, puis intÃ©grÃ© dans une application interactive via **Gradio**.

---

## ğŸ“ Structure du projet

```
.
â”œâ”€â”€ bertclassifiactiontext.ipynb   # Entrainement et Ã©valuation du modÃ¨le NewsClassifier
â”œâ”€â”€ bertclassifiactiontext.py   # DÃ©finition du modÃ¨le NewsClassifier
â”œâ”€â”€ demo.py                     # Interface Gradio pour la prÃ©diction
â”œâ”€â”€ saved_model_bert/          # ModÃ¨le entraÃ®nÃ© et tokenizer sauvegardÃ©s
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ model.pt
â”‚   â””â”€â”€ vocab.txt
â””â”€â”€ requirements.txt                   # DÃ©pendances du projet
â””â”€â”€ README.md                   # Fichier dâ€™explication (ce fichier)
```

---

## ğŸ—ï¸ Ã‰tapes de rÃ©alisation

### 1. ğŸ”¨ EntraÃ®nement du modÃ¨le (`bertclassifiactiontext.ipynb`)
Le modÃ¨le est basÃ© sur la classe `BertModel` de Hugging Face. Il comprend :

- Une couche BERT prÃ©-entraÃ®nÃ©e
- Une couche `Dropout`
- Une couche linÃ©aire pour la classification

```python
class NewsClassifier(nn.Module):
    def __init__(self, num_classes):
        super(NewsClassifier, self).__init__()
        self.bert = BertModel.from_pretrained(config.model)
        self.drop = nn.Dropout(0.3)
        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)

    def forward(self, input_ids, attention_mask):
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        pooled_output = outputs.pooler_output
        return self.fc(self.drop(pooled_output))
```

---

### 2. âœ… Chargement et prÃ©diction (`demo.py`)

- Chargement du tokenizer et du modÃ¨le sauvegardÃ©
- PrÃ©diction via `torch.softmax` pour obtenir les probabilitÃ©s
- Retour de lâ€™Ã©tiquette prÃ©dite et du score de confiance

Les champs **titre** et **contenu** sont saisis sÃ©parÃ©ment dans lâ€™interface, mais **ne sont pas fusionnÃ©s**. Seul le champ "contenu" est utilisÃ© pour la prÃ©diction :

```python
def predict(content):
    inputs = tokenizer(content, return_tensors="pt", truncation=True, padding=True, max_length=512)
    ...
```

---

### 3. ğŸ–¼ï¸ Interface Gradio

```python
demo = gr.Interface(
    fn=predict,
    inputs=[
        gr.Textbox(label="Titre de l'article"),
        gr.Textbox(label="Contenu de l'article", lines=5),
    ],
    outputs=gr.Textbox(label="PrÃ©diction"),
    title="DÃ©mo BERT : Classification d'Articles",
    description="Entrez un titre et un texte pour prÃ©dire la catÃ©gorie"
)
```

Ajoutez `share=True` pour gÃ©nÃ©rer un lien public :

```python
demo.launch(share=True)
```

---

## ğŸ§ª Exemple

EntrÃ©e :
- **Titre** : â€œLa prÃ©sidente signe un nouveau dÃ©cretâ€
- **Contenu** : â€œDans un discours au parlement, la prÃ©sidente a annoncÃ©...â€

Sortie :
> `Politics News â€” confiance : 91.25%`

---

## ğŸ“¦ Installation des dÃ©pendances

```bash
pip install torch transformers gradio
pip install -r requirements.txt
```

---

## ğŸš€ Lancer lâ€™application

```bash
python demo.py
```

---

## ğŸ“Œ Notes

- Pour une classification multi-classes, augmentez la valeur de `num_classes`.
- Le tokenizer et le modÃ¨le doivent Ãªtre sauvegardÃ©s dans le dossier `saved_model_bert/`.
- Le modÃ¨le ne fusionne pas les champs "titre" et "contenu" pour la prÃ©diction.
